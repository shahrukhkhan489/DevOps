######## Pre-requistes ##########

- name: yum-clean-all
  command: yum clean all
  args:
    warn: no

- name: Install NTP service
  yum:
    name: ntp
    state: installed
  ignore_errors: true

- name: Install Unzip service
  yum:
    name: unzip
    state: installed
  ignore_errors: true

- name: Make sure the NTP service is enabled
  service:
    name: ntpd
    enabled: yes
  ignore_errors: true

- name: Set swappiness to 0
  sysctl:
    name: vm.swappiness
    value: 0
    state: present
    reload: yes
    ignoreerrors: yes

- name: Stop the iptables service
  service:
    name: iptables
    state: stopped
  ignore_errors: true

- name: Disable the iptables firewall service
  service:
    name: iptables
    enabled: no
  ignore_errors: true

- name: Stop the firewalld service
  service:
    name: firewalld
    state: stopped
  ignore_errors: true

- name: Disable the firewalld firewall service
  service:
    name: firewalld
    enabled: no
  ignore_errors: true

- name: Disable Transparent Huge Pages until the next reboot
  shell: echo never > /sys/kernel/mm/transparent_hugepage/enabled && echo never > /sys/kernel/mm/transparent_hugepage/defrag
  args:
    removes: /sys/kernel/mm/transparent_hugepage/enabled

- name: Install epel
  yum:
    name: epel-release
    state: installed
  ignore_errors: true

- name: Disable selinux
  selinux:
    state: disabled

- name: Check if umask Value exists
  command: grep "umask 0022" /etc/profile
  register: umask
  always_run: True
  ignore_errors: True
  changed_when: False

- name: Updating umask Value
  shell: echo umask 0022 >> /etc/profile
  when: umask.rc != 0

######### Setup Hadoop ##############

- name: Install OpenJDK-1.8
  yum:
    name: java-1.8.0-openjdk
    state: installed

- name: Install OpenJDK-1.8 Devel Packages
  yum:
    name: java-1.8.0-openjdk-devel
    state: installed

- name: Downloading Hadoop 3.0 Distribution
  get_url: url='http://apachemirror.wuchna.com/hadoop/common/stable/hadoop-3.2.1.tar.gz' dest='/tmp/hadoop-3.2.1.tar.gz' mode=0644

- name: Unarchive Hadoop
  unarchive:
    src: /tmp/hadoop-3.2.1.tar.gz
    dest: /usr/
    remote_src: yes

- name: Setup Hadoop Enviornment Variables
  blockinfile:
    path: /usr/hadoop-3.2.1/etc/hadoop/hadoop-env.sh
    block: |
      export JAVA_HOME=/etc/alternatives/jre_openjdk
      export HDFS_NAMENODE_USER="root"
      export HDFS_DATANODE_USER="root"
      export HDFS_SECONDARYNAMENODE_USER="root"
      export YARN_RESOURCEMANAGER_USER="root"
      export YARN_NODEMANAGER_USER="root"

- name: Create Hadoop Env File
  file:
    state: touch
    path: /etc/profile.d/hadoop.sh

- name: Setup Hadoop bin Path
  blockinfile:
    path: /etc/profile.d/hadoop.sh
    block: |
      export PATH="$PATH:/usr/hadoop-3.2.1/bin/"

- name: Format Namenode
  shell: |
    ssh-keygen -t rsa -P '' -f ~/.ssh/id_rsa
    cat ~/.ssh/id_rsa.pub >> ~/.ssh/authorized_keys
    chmod 0600 ~/.ssh/authorized_keys

- name: Update Core Site
  xml:
    path: /usr/hadoop-3.2.1/etc/hadoop/core-site.xml
    xpath: /configuration/property
    attribute: fs.defaultFS
    value: hdfs://localhost:9000

- name: Update HDFS Site
  xml:
    path: /usr/hadoop-3.2.1/etc/hadoop/hdfs-site.xml
    xpath: /configuration/property
    attribute: dfs.replication
    value: '1'

- name: Format Namenode
  shell: /usr/hadoop-3.2.1/bin/hdfs namenode -format


######## Setup Hadoop Servcies ##############


chmod +x /etc/init.d/hadoop
chkconfig --add hadoop
service hadoop start



# - name: Start HDFS
#   shell: /usr/hadoop-3.2.1/sbin/start-dfs.sh
